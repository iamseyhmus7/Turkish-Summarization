# ğŸ‡¹ğŸ‡· Turkish Summarization with mT5

Bu proje, **TÃ¼rkÃ§e metin Ã¶zetleme** gÃ¶revini gerÃ§ekleÅŸtirmek Ã¼zere **mT5-small** modelinin **tam (full) fine-tuning** yÃ¶ntemiyle eÄŸitilmesiyle geliÅŸtirilmiÅŸtir.  
EÄŸitimde, Hugging Face Ã¼zerinde yer alan [`gullnihal/mlsum_tr`](https://huggingface.co/datasets/gullnihal/mlsum_tr) veri seti kullanÄ±lmÄ±ÅŸtÄ±r.

## ğŸš€ Ã–zellikler
- **mT5-small** modeli ile TÃ¼rkÃ§e metin Ã¶zetleme
- Hem **metin girdisi** hem de **PDF belgelerinin** Ã¶zetlenmesi
- Hugging Face Spaces Ã¼zerinde canlÄ± demo
- Basit ve hÄ±zlÄ± kullanÄ±m

## ğŸ“‚ Veri Seti
- Kaynak: [`gullnihal/mlsum_tr`](https://huggingface.co/datasets/gullnihal/mlsum_tr)
- TÃ¼rkÃ§e haber metinlerinden oluÅŸur
- EÄŸitim/DoÄŸrulama/Test ayrÄ±mÄ± hazÄ±r

## ğŸ› ï¸ EÄŸitim SÃ¼reci
- **Model:** `google/mt5-small`
- **Fine-tuning:** Tam model aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellendi (full fine-tuning)
- **AmaÃ§:** Uzun TÃ¼rkÃ§e metinlerin anlam bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ koruyarak kÄ±sa Ã¶zetler Ã¼retmek
- **DonanÄ±m:** Google Colab T4 / A100

## ğŸ“¦ KullanÄ±m
### Hugging Face ile
```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

model_name = "iamseyhmus7/turkish-summarization"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

text = "TÃ¼rkiye'nin ilk astronotu Alper GezeravcÄ±, ISS'teki gÃ¶revini tamamladÄ±."
inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True)

summary_ids = model.generate(**inputs, max_length=64, min_length=10)
print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))
